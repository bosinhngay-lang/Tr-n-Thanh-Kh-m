
import os
import numpy as np
import pandas as pd
import streamlit as st

# Optional: set PyTensor flags externally if needed (e.g., avoid C++ JIT on Windows)
# os.environ["PYTENSOR_FLAGS"] = "cxx=,mode=FAST_COMPILE,optimizer=None"

# Optional PyMC imports
try:
    import pymc as pm
    import arviz as az
    _PYMC_AVAILABLE = True
except Exception:
    pm = None
    az = None
    _PYMC_AVAILABLE = False

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,
    roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay
)

# CalibrationDisplay may not exist in older scikit-learn versions
try:
    from sklearn.calibration import CalibrationDisplay
    _HAS_CALIB = True
except Exception:
    CalibrationDisplay = None
    _HAS_CALIB = False

import matplotlib.pyplot as plt

# ========= Page config =========
st.set_page_config(page_title="Student Performance ‚Äî Logistic (MLE) & Bayesian", layout="wide")

st.title("üéì Student Performance ‚Äî Logistic (MLE) & Bayesian (Laplace / PyMC)")
st.caption("Upload CSV ‚Üí auto-detect target ‚Üí Logistic (MLE) + Bayesian (Laplace or PyMC). Compact plots, rich explanations, parameter guides, threshold tuning, and lift/gains.")

# ========= Quick Start =========
with st.expander("üöÄ Quick Start (Read me first)", expanded=False):
    st.markdown("""
**Steps**
1. **Upload** your CSV (rows = students, columns = features + target).  
2. The app **auto-detects** the **target**; adjust if needed. Continuous targets are **auto-binarized** with a balanced threshold.
3. Adjust sidebar **parameters** (with tooltips).
4. Review **Descriptive** ‚Üí class balance & correlations.
5. Train **Logistic (MLE)** and **Bayesian** (Laplace or PyMC).  
6. Use **Threshold & Gains** to tune the decision threshold, and **Predict** to try custom inputs.

**Tip:** For imbalanced data, start with `class_weight='balanced'` and tune the threshold for your business goal (e.g., recall).
""")

# ========= Sidebar: global controls =========
st.sidebar.header("‚öôÔ∏è Global Settings")
test_size = st.sidebar.slider("Test size", 0.10, 0.40, 0.25, 0.01,
                              help="Ph·∫ßn trƒÉm d·ªØ li·ªáu d√†nh cho ki·ªÉm tra (test). 0.25 = 25% test, 75% train.")
random_state = st.sidebar.number_input("Random seed", value=42, step=1,
                                       help="Gi·ªØ c·ªë ƒë·ªãnh ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£ chia train/test.")
plot_scale = st.sidebar.slider("Plot size scale", 0.6, 1.6, 0.9, 0.05,
                               help="Thu/ph√≥ng to√†n b·ªô bi·ªÉu ƒë·ªì ƒë·ªÉ g·ªçn g√†ng h∆°n.")

# Apply scaled font sizes
plt.rcParams.update({
    "axes.titlesize": 12*plot_scale,
    "axes.labelsize": 11*plot_scale,
    "xtick.labelsize": 10*plot_scale,
    "ytick.labelsize": 10*plot_scale,
    "legend.fontsize": 10*plot_scale,
})

def make_fig(w=5, h=3):
    """Create a small figure scaled by plot_scale."""
    fig, ax = plt.subplots(figsize=(w*plot_scale, h*plot_scale))
    return fig, ax

# ========= Parameter Guide =========
with st.expander("üìò Parameter Guide & How They Affect Predictions", expanded=False):
    st.markdown("""
### Data split
- **Test size**: ph·∫ßn trƒÉm d·ªØ li·ªáu gi·ªØ l·∫°i ƒë·ªÉ ƒëo l∆∞·ªùng (kh√¥ng d√πng ƒë·ªÉ hu·∫•n luy·ªán).

### Logistic (MLE)
- **Penalty**
  - **None (MLE)** = kh√¥ng ph·∫°t ‚Üí ∆∞·ªõc l∆∞·ª£ng c·ª±c ƒë·∫°i kh·∫£ nƒÉng (t·ªëi ƒëa h√≥a likelihood).
  - **L2** (Ridge) ‚Üí **co** h·ªá s·ªë v·ªÅ 0 ‚Üí ·ªïn ƒë·ªãnh, ch·ªëng overfit.
- **C (khi L2)**: **C l·ªõn ‚Üí ph·∫°t y·∫øu** (g·∫ßn MLE). **C nh·ªè ‚Üí ph·∫°t m·∫°nh** (x√°c su·∫•t ‚Äúd·ªãu‚Äù h∆°n, √≠t c·ª±c tr·ªã).
- **Solver**
  - **lbfgs**: ·ªïn ƒë·ªãnh, nhanh cho d·ªØ li·ªáu v·ª´a.
  - **saga**: linh ho·∫°t, t·ªët cho d·ªØ li·ªáu th∆∞a/l·ªõn.
- **Class weight**
  - **balanced** ƒë·ªëi ph√≥ l·ªách l·ªõp: th∆∞·ªùng tƒÉng **Recall** l·ªõp thi·∫øu nh∆∞ng c√≥ th·ªÉ gi·∫£m **Precision**.

### Bayesian (Laplace)
- **Prior œÉ (weights/intercept)**: ƒë·ªô l·ªách chu·∫©n prior Gaussian.
  - **œÉ l·ªõn** ‚Üí prior y·∫øu (h·ªá s·ªë linh ho·∫°t).
  - **œÉ nh·ªè** ‚Üí prior m·∫°nh (co v·ªÅ 0). K·∫øt qu·∫£ **b·∫£o th·ªß** h∆°n.

### Bayesian (PyMC sampling)
- **draws/tune**: nhi·ªÅu h∆°n ‚Üí posterior m∆∞·ª£t h∆°n, ch·∫≠m h∆°n.
- **target_accept**: 0.9‚Äì0.95 an to√†n h∆°n, ch·∫≠m h∆°n.
- **chains/cores**: nhi·ªÅu chains ƒë·ªÉ ki·ªÉm tra h·ªôi t·ª•.

### ·∫¢nh h∆∞·ªüng l√™n d·ª± ƒëo√°n
- Regularization m·∫°nh (L2 v·ªõi **C nh·ªè**, ho·∫∑c **œÉ nh·ªè**) ‚Üí h·ªá s·ªë nh·ªè h∆°n ‚Üí x√°c su·∫•t d·ª± ƒëo√°n **√≠t c·ª±c tr·ªã** (g·∫ßn 0.5), m√¥ h√¨nh **b·∫£o th·ªß**.
- **balanced** gi√∫p b·∫Øt ƒë∆∞·ª£c nhi·ªÅu l·ªõp thi·ªÉu s·ªë (**Recall‚Üë**) nh∆∞ng c√≥ th·ªÉ hi sinh **Precision**.
- Priors (Bayesian) cung c·∫•p **ƒë·ªô b·∫•t ƒë·ªãnh** (uncertainty) ƒë·ªÉ ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n r·ªßi ro.
""")

# ========= Helpers =========
CANDIDATE_TARGET_NAMES = ["Score","score","grade","passed","pass","target","label","y","outcome","result","performance"]

def safe_read_csv(file) -> pd.DataFrame:
    encodings_to_try = ["utf-8", "utf-8-sig", "latin1", "cp1252", "cp1258"]
    seps_to_try = [",", ";", "\t", "|"]
    for enc in encodings_to_try:
        for sep in seps_to_try:
            try:
                file.seek(0)
                df = pd.read_csv(file, encoding=enc, sep=sep)
                return df
            except Exception:
                continue
    st.error("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c CSV v·ªõi c√°c encoding/sep ph·ªï bi·∫øn.")
    st.stop()

def infer_target_column(df: pd.DataFrame):
    cols_lower = {c.lower(): c for c in df.columns}
    for name in CANDIDATE_TARGET_NAMES:
        if name.lower() in cols_lower:
            return cols_lower[name.lower()]
    return df.columns[-1]

def is_binary_series(s: pd.Series) -> bool:
    vals = pd.unique(s.dropna())
    try:
        vals = set([int(v) if str(v).isdigit() else v for v in vals])
    except Exception:
        vals = set(vals)
    return vals.issubset({0,1,True,False})

def binarize_continuous(y: pd.Series):
    vals = pd.to_numeric(y, errors="coerce")
    lo, hi = vals.quantile(0.2), vals.quantile(0.8)
    candidates = np.linspace(lo, hi, 51)
    best_thr, best_balance = candidates[0], -1.0
    for thr in candidates:
        y_tmp = (vals >= thr).astype(int)
        balance = 1 - abs(y_tmp.mean() - 0.5)*2
        if balance > best_balance:
            best_balance, best_thr = balance, thr
    return (vals >= best_thr).astype(int), float(best_thr), float((vals >= best_thr).mean())

def summarize_metrics(y_true, y_pred, y_proba=None):
    out = {}
    out["Accuracy"]  = accuracy_score(y_true, y_pred)
    out["Precision"] = precision_score(y_true, y_pred, zero_division=0)
    out["Recall"]    = recall_score(y_true, y_pred, zero_division=0)
    out["F1"]        = f1_score(y_true, y_pred, zero_division=0)
    if y_proba is not None:
        try:
            out["ROC AUC"] = roc_auc_score(y_true, y_proba)
        except Exception:
            out["ROC AUC"] = None
    return out

def to_dense(X):
    try:
        return X.toarray()
    except Exception:
        return np.asarray(X)

def build_design_matrix(preprocess, X_df):
    Z = preprocess.transform(X_df)
    return to_dense(Z)

def laplace_posterior(Z, w, b, prior_var_w, prior_var_b):
    n, d = Z.shape
    eta = Z @ w + b
    p = 1.0 / (1.0 + np.exp(-eta))
    W = p * (1 - p)
    Z_aug = np.hstack([np.ones((n,1)), Z])
    prior_prec = np.diag(np.concatenate([[1.0/prior_var_b], np.full(d, 1.0/prior_var_w)]))
    A = (Z_aug.T * W) @ Z_aug
    precision = A + prior_prec
    try:
        cov = np.linalg.inv(precision)
    except np.linalg.LinAlgError:
        cov = np.linalg.pinv(precision)
    return cov

def bayes_pred_prob_with_variance_correction(m, v):
    # Approx E[sigmoid(N(m,v))] ‚âà sigmoid( m / sqrt(1 + pi*v/8) )
    denom = np.sqrt(1.0 + np.pi * v / 8.0)
    return 1.0 / (1.0 + np.exp(-m/denom))

def make_mle_logreg(class_weight, solver, C, penalty):
    try:
        return LogisticRegression(
            penalty=penalty, C=C, solver=solver, max_iter=1000, class_weight=class_weight
        )
    except Exception:
        # Fallback emulate MLE via large C L2
        return LogisticRegression(
            penalty="l2", C=1e9, solver="lbfgs", max_iter=1000, class_weight=class_weight
        )

# ========= Sidebar: model-specific controls =========
st.sidebar.subheader("Logistic (MLE)")
penalty_opt = st.sidebar.selectbox("Penalty", ["None (MLE)", "L2"], index=0,
                                   help="None = kh√¥ng ph·∫°t (MLE). L2 = Ridge (co h·ªá s·ªë v·ªÅ 0).")
solver_opt = st.sidebar.selectbox("Solver", ["lbfgs", "saga"], index=0,
                                  help="lbfgs: ·ªïn ƒë·ªãnh, nhanh. saga: linh ho·∫°t, t·ªët cho d·ªØ li·ªáu th∆∞a.")
C_val = st.sidebar.number_input("C (n·∫øu L2, l·ªõn ~ MLE)", min_value=1e-4, max_value=1e12, value=1e6, step=1e4, format="%.4f",
                                help="C l·ªõn ‚Üí ph·∫°t y·∫øu; C nh·ªè ‚Üí ph·∫°t m·∫°nh.")
cw_opt = st.sidebar.selectbox("Class weight", ["None", "balanced"], index=1,
                              help="balanced gi√∫p v·ªõi l·ªách l·ªõp, th∆∞·ªùng tƒÉng Recall nh∆∞ng gi·∫£m Precision.")

st.sidebar.subheader("Bayesian method")
bayes_method = st.sidebar.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p", ["Laplace (nhanh)", "PyMC sampling"], index=0,
                                    help="Laplace: nhanh, kh√¥ng c·∫ßn compiler. PyMC: posterior ch√≠nh x√°c h∆°n nh∆∞ng c·∫ßn toolchain.")
st.sidebar.caption("üí° N·∫øu PyMC l·ªói bi√™n d·ªãch tr√™n Windows, app s·∫Ω t·ª± fallback sang Laplace.")

with st.sidebar.expander("Bayesian (Laplace) params", expanded=(bayes_method=="Laplace (nhanh)")):
    prior_sigma_w = st.slider("Prior œÉ (weights)", 0.1, 100.0, 10.0, 0.1,
                              help="œÉ l·ªõn ‚Üí prior y·∫øu (√≠t co). œÉ nh·ªè ‚Üí prior m·∫°nh (co nhi·ªÅu).")
    prior_sigma_b = st.slider("Prior œÉ (intercept)", 0.1, 100.0, 10.0, 0.1,
                              help="T∆∞∆°ng t·ª± cho intercept.")

with st.sidebar.expander("Bayesian (PyMC) params", expanded=(bayes_method=="PyMC sampling")):
    draws = st.number_input("draws", min_value=200, max_value=3000, value=1000, step=50,
                            help="S·ªë m·∫´u posterior sau warmup.")
    tune = st.number_input("tune", min_value=200, max_value=3000, value=1000, step=50,
                           help="S·ªë b∆∞·ªõc warmup (ƒëi·ªÅu ch·ªânh NUTS).")
    target_accept = st.slider("target_accept", 0.80, 0.98, 0.90, 0.01,
                              help="Cao h∆°n ‚Üí √≠t b∆∞·ªõc b·ªã t·ª´ ch·ªëi h∆°n nh∆∞ng ch·∫≠m h∆°n.")
    chains = st.number_input("chains", min_value=1, max_value=4, value=2, step=1,
                             help="S·ªë chu·ªói ƒë·ªôc l·∫≠p ƒë·ªÉ ki·ªÉm tra h·ªôi t·ª•.")
    cores = st.number_input("cores", min_value=1, max_value=2, value=1, step=1,
                            help="S·ªë l√µi CPU ƒë·ªÉ ch·∫°y song song.")
    prior_sigma_beta_pymc = st.number_input("prior_sigma_beta", min_value=0.1, max_value=100.0, value=10.0, step=0.1,
                                            help="Prior œÉ cho h·ªá s·ªë (PyMC).")
    prior_sigma_intercept_pymc = st.number_input("prior_sigma_intercept", min_value=0.1, max_value=100.0, value=10.0, step=0.1,
                                                 help="Prior œÉ cho intercept (PyMC).")

# ========= Upload & target =========
file = st.file_uploader("üìÇ Upload CSV", type=["csv"])
if not file:
    st.info("H√£y upload file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

df = safe_read_csv(file)
st.subheader("üîé Preview d·ªØ li·ªáu")
st.dataframe(df.head())

default_target = "Score" if "Score" in df.columns else infer_target_column(df)
target_col = st.selectbox("üéØ Ch·ªçn c·ªôt target", options=list(df.columns), index=list(df.columns).index(default_target))

y_raw = df[target_col]
X_raw = df.drop(columns=[target_col])

if is_binary_series(y_raw):
    st.success(f"Target `{target_col}` ƒë√£ nh·ªã ph√¢n ‚Üí d√πng tr·ª±c ti·∫øp (0/1).")
    y = y_raw.astype(int).replace({True:1, False:0})
    selected_threshold = None
else:
    y, selected_threshold, cls1_rate = binarize_continuous(y_raw)
    st.warning(f"`{target_col}` l√† li√™n t·ª•c ‚Üí **auto-binarize** t·∫°i ng∆∞·ª°ng **{selected_threshold:.4f}** (t·ª∑ l·ªá l·ªõp 1 ‚âà {cls1_rate:.2%}).")
    st.caption("Ng∆∞·ª°ng ƒë∆∞·ª£c t√¨m ƒë·ªÉ c√¢n b·∫±ng g·∫ßn 50/50 gi√∫p m√¥ h√¨nh ·ªïn ƒë·ªãnh h∆°n. B·∫°n c√≥ th·ªÉ tinh ch·ªânh ng∆∞·ª°ng trong m·ª•c **Threshold & Gains**.")

# ========= Split & preprocess =========
X_train, X_test, y_train, y_test = train_test_split(
    X_raw, y, test_size=test_size, random_state=random_state, stratify=y
)

numeric_cols = [c for c in X_raw.columns if np.issubdtype(df[c].dtype, np.number)]
categorical_cols = [c for c in X_raw.columns if c not in numeric_cols]

numeric_tf = Pipeline([("imputer", SimpleImputer(strategy="median")),
                       ("scaler", StandardScaler())])
categorical_tf = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")),
                           ("onehot", OneHotEncoder(handle_unknown="ignore"))])
preprocess = ColumnTransformer([
    ("num", numeric_tf, numeric_cols),
    ("cat", categorical_tf, categorical_cols)
])
preprocess.fit(X_train)

# ========= Data Health Checks =========
with st.expander("ü©∫ Data Health Checks (types ‚Ä¢ missing ‚Ä¢ cardinality)", expanded=False):
    info = []
    for c in X_raw.columns:
        s = X_raw[c]
        missing = float(s.isna().mean()) if len(s) else 0.0
        unique = int(s.nunique(dropna=True))
        dtype = str(s.dtype)
        row = {"column": c, "dtype": dtype, "%missing": round(missing*100,2), "unique": unique}
        if np.issubdtype(s.dtype, np.number):
            try:
                row.update({"mean": float(pd.to_numeric(s, errors="coerce").mean()),
                            "std": float(pd.to_numeric(s, errors="coerce").std())})
            except Exception:
                pass
        else:
            try:
                top_vals = pd.Series(s.astype(str)).value_counts().head(5).index.tolist()
                row["top_values"] = ", ".join(map(str, top_vals))
            except Exception:
                row["top_values"] = ""
        info.append(row)
    st.dataframe(pd.DataFrame(info))

    st.caption("**G·ª£i √Ω**: %missing cao ‚Üí c·∫ßn thu th·∫≠p th√™m d·ªØ li·ªáu ho·∫∑c c√¢n nh·∫Øc k·ªπ chi·∫øn l∆∞·ª£c impute. Cardinality qu√° l·ªõn ·ªü categorical ‚Üí one-hot c√≥ th·ªÉ n·ªü chi·ªÅu.")

# ========= Descriptive (smaller + explanations) =========
st.header("üß≠ Descriptive")

fig_bal, ax_bal = make_fig(4.5, 3.0)
y_counts = pd.Series(y).value_counts().sort_index()
ax_bal.bar(y_counts.index.astype(str), y_counts.values)
ax_bal.set_title("Class Balance")
ax_bal.set_xlabel("Class")
ax_bal.set_ylabel("Count")
st.pyplot(fig_bal, use_container_width=True)
st.caption("**√ù nghƒ©a**: Ki·ªÉm tra ƒë·ªô c√¢n b·∫±ng gi·ªØa hai l·ªõp. L·ªách l·ªõp m·∫°nh ‚Üí c√¢n nh·∫Øc `class_weight='balanced'` v√† ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng.")

if len(numeric_cols) >= 2:
    try:
        corr = pd.DataFrame(X_train[numeric_cols]).corr()
        fig_corr, ax_corr = make_fig(5.0, 3.2)
        im = ax_corr.imshow(corr, aspect='auto')
        ax_corr.set_xticks(range(len(numeric_cols))); ax_corr.set_xticklabels(numeric_cols, rotation=90)
        ax_corr.set_yticks(range(len(numeric_cols))); ax_corr.set_yticklabels(numeric_cols)
        ax_corr.set_title("Correlation (numeric)")
        fig_corr.colorbar(im, ax=ax_corr, fraction=0.046, pad=0.04)
        st.pyplot(fig_corr, use_container_width=True)
        st.caption("**Gi·∫£i th√≠ch**: T∆∞∆°ng quan cao gi·ªØa bi·∫øn s·ªë c√≥ th·ªÉ l√†m h·ªá s·ªë kh√≥ di·ªÖn gi·∫£i; c√¢n nh·∫Øc regularization ho·∫∑c PCA/feature selection.")
    except Exception:
        st.info("Kh√¥ng v·∫Ω ƒë∆∞·ª£c heatmap t∆∞∆°ng quan.")

# ========= Logistic (MLE) =========
st.header("‚öôÔ∏è Logistic Regression (MLE)")
class_weight = None if cw_opt == "None" else "balanced"
penalty = None if penalty_opt.startswith("None") else "l2"
solver = solver_opt
C_for_model = float(C_val)

mle_clf = make_mle_logreg(class_weight, solver, C_for_model, penalty)
mle_pipe = Pipeline([("preprocess", preprocess), ("clf", mle_clf)])
mle_pipe.fit(X_train, y_train)

y_pred_mle = mle_pipe.predict(X_test)
try:
    y_proba_mle = mle_pipe.predict_proba(X_test)[:, 1]
except Exception:
    y_proba_mle = None

mle_metrics = summarize_metrics(y_test, y_pred_mle, y_proba_mle)

c1, c2, c3, c4 = st.columns(4)
with c1: st.metric("Accuracy", f"{mle_metrics['Accuracy']:.3f}")
with c2: st.metric("Precision", f"{mle_metrics['Precision']:.3f}")
with c3: st.metric("Recall", f"{mle_metrics['Recall']:.3f}")
with c4: st.metric("F1", f"{mle_metrics['F1']:.3f}")
if y_proba_mle is not None and mle_metrics.get("ROC AUC") is not None:
    st.metric("ROC AUC", f"{mle_metrics['ROC AUC']:.3f}")
st.caption("**G·ª£i √Ω**: Recall th·∫•p cho l·ªõp 1? ‚Üí d√πng `balanced` v√†/ho·∫∑c gi·∫£m ng∆∞·ª°ng. Precision th·∫•p? ‚Üí tƒÉng ng∆∞·ª°ng.")

cm = confusion_matrix(y_test, y_pred_mle)
st.write("**Confusion Matrix (MLE)**")
st.write(pd.DataFrame(cm, index=["Actual 0", "Actual 1"], columns=["Pred 0", "Pred 1"]))
st.caption("**TN/FP/FN/TP**: False Positive t·ªën chi ph√≠ do c·∫£nh b√°o sai; False Negative t·ªën chi ph√≠ do b·ªè s√≥t.")

if y_proba_mle is not None:
    colA, colB, colC = st.columns(3)
    with colA:
        fig, ax = make_fig(4.0, 3.0)
        RocCurveDisplay.from_predictions(y_test, y_proba_mle, ax=ax)
        ax.set_title("ROC ‚Äî MLE")
        st.pyplot(fig, use_container_width=True)
        st.caption("**ROC**: AUC c√†ng cao c√†ng t·ªët; ƒëo kh·∫£ nƒÉng x·∫øp h·∫°ng ƒë√∫ng x√°c su·∫•t.")

    with colB:
        fig_pr, ax_pr = make_fig(4.0, 3.0)
        PrecisionRecallDisplay.from_predictions(y_test, y_proba_mle, ax=ax_pr)
        ax_pr.set_title("PR ‚Äî MLE")
        st.pyplot(fig_pr, use_container_width=True)
        st.caption("**PR**: h·ªØu √≠ch khi d·ªØ li·ªáu l·ªách l·ªõp; trade-off gi·ªØa Precision v√† Recall.")

    with colC:
        if _HAS_CALIB:
            fig_cal, ax_cal = make_fig(4.0, 3.0)
            CalibrationDisplay.from_predictions(y_test, y_proba_mle, n_bins=10, strategy="uniform", ax=ax_cal)
            ax_cal.set_title("Calibration ‚Äî MLE")
            st.pyplot(fig_cal, use_container_width=True)
            st.caption("**Calibration**: ƒë∆∞·ªùng g·∫ßn ch√©o ‚Üí x√°c su·∫•t d·ª± ƒëo√°n ph·∫£n √°nh t·∫ßn su·∫•t th·ª±c.")
        else:
            st.info("Calibration plot requires newer scikit-learn.")

# Coefficients ‚Äî MLE (Top 10 by |coef|)
try:
    preproc = mle_pipe.named_steps["preprocess"]
    clf = mle_pipe.named_steps["clf"]
    ohe = preproc.named_transformers_["cat"].named_steps["onehot"] if len(categorical_cols) else None
    cat_names = list(ohe.get_feature_names_out(categorical_cols)) if ohe is not None else []
    feature_names = list(numeric_cols) + cat_names
    coefs = clf.coef_.ravel()
    coef_df = pd.DataFrame({"feature": feature_names, "coef": coefs})
    top10_mle = (coef_df.assign(abs_coef=lambda d: d["coef"].abs())
                         .sort_values("abs_coef", ascending=False)
                         .head(10)
                         .sort_values("coef"))
    fig_b_mle, ax_b_mle = make_fig(5.2, max(2.6, len(top10_mle)/12))
    ax_b_mle.barh(top10_mle["feature"], top10_mle["coef"])
    ax_b_mle.set_title("MLE Coefficients (Top 10 by |coef|)")
    st.pyplot(fig_b_mle, use_container_width=True)
    st.caption("**Di·ªÖn gi·∫£i**: H·ªá s·ªë d∆∞∆°ng ‚Üí tƒÉng x√°c su·∫•t l·ªõp 1 khi bi·∫øn tƒÉng (gi·ªØ c√°c bi·∫øn kh√°c c·ªë ƒë·ªãnh). L∆∞u √Ω: input ƒë√£ chu·∫©n ho√° & one-hot, h·ªá s·ªë ph·ª• thu·ªôc baseline c·ªßa one-hot.")
except Exception:
    st.info("Kh√¥ng l·∫•y ƒë∆∞·ª£c h·ªá s·ªë MLE.")

# ========= Bayesian =========
st.header("üßÆ Bayesian Logistic Regression")

if bayes_method == "Laplace (nhanh)":
    C_map = prior_sigma_w**2
    map_clf = LogisticRegression(penalty="l2", C=C_map, solver="lbfgs", max_iter=1000, class_weight=class_weight)
    map_pipe = Pipeline([("preprocess", preprocess), ("clf", map_clf)])
    map_pipe.fit(X_train, y_train)
    y_pred_map = map_pipe.predict(X_test)
    y_proba_map = map_pipe.predict_proba(X_test)[:, 1]

    map_mets = summarize_metrics(y_test, y_pred_map, y_proba_map)
    c1, c2, c3, c4 = st.columns(4)
    with c1: st.metric("Accuracy (MAP)", f"{map_mets['Accuracy']:.3f}")
    with c2: st.metric("Precision (MAP)", f"{map_mets['Precision']:.3f}")
    with c3: st.metric("Recall (MAP)", f"{map_mets['Recall']:.3f}")
    with c4: st.metric("F1 (MAP)", f"{map_mets['F1']:.3f}")
    st.metric("ROC AUC (MAP)", f"{map_mets.get('ROC AUC', float('nan')):.3f}")
    st.caption("**MAP ‚âà Logistic L2** v·ªõi **C‚âàœÉ¬≤** (prior Gaussian).")

    cm_map = confusion_matrix(y_test, y_pred_map)
    st.write("**Confusion Matrix (MAP)**")
    st.write(pd.DataFrame(cm_map, index=["Actual 0", "Actual 1"], columns=["Pred 0", "Pred 1"]))

    rowA, rowB, rowC = st.columns(3)
    with rowA:
        fig2, ax2 = make_fig(4.0, 3.0)
        RocCurveDisplay.from_predictions(y_test, y_proba_map, ax=ax2)
        ax2.set_title("ROC ‚Äî MAP")
        st.pyplot(fig2, use_container_width=True)
    with rowB:
        fig_pr2, ax_pr2 = make_fig(4.0, 3.0)
        PrecisionRecallDisplay.from_predictions(y_test, y_proba_map, ax=ax_pr2)
        ax_pr2.set_title("PR ‚Äî MAP")
        st.pyplot(fig_pr2, use_container_width=True)
    with rowC:
        if _HAS_CALIB:
            fig_cal2, ax_cal2 = make_fig(4.0, 3.0)
            CalibrationDisplay.from_predictions(y_test, y_proba_map, n_bins=10, strategy="uniform", ax=ax_cal2)
            ax_cal2.set_title("Calibration ‚Äî MAP")
            st.pyplot(fig_cal2, use_container_width=True)
        else:
            st.info("Calibration plot requires newer scikit-learn.")

    # Laplace covariance & coefficient uncertainty
    Z_train = build_design_matrix(preprocess, X_train)
    w_map = map_pipe.named_steps["clf"].coef_.ravel()
    b_map = float(map_pipe.named_steps["clf"].intercept_[0])
    Sigma = laplace_posterior(
        Z_train, w_map, b_map, prior_var_w=prior_sigma_w**2, prior_var_b=prior_sigma_b**2
    )

    diag_Sigma = np.diag(Sigma)
    st.caption(f"**Laplace posterior Œ£**: shape {Sigma.shape}, trace ‚âà {diag_Sigma.sum():.3f} (b·∫•t ƒë·ªãnh t·ªïng qu√°t).")

    try:
        ohe_map = preprocess.named_transformers_["cat"].named_steps["onehot"] if len(categorical_cols) else None
        cat_names_map = list(ohe_map.get_feature_names_out(categorical_cols)) if ohe_map is not None else []
        feature_names_map = list(numeric_cols) + cat_names_map
        se = np.sqrt(diag_Sigma[1:1+len(feature_names_map)])
        coef_df_map = pd.DataFrame({"feature": feature_names_map, "coef": w_map, "se": se})
        top10 = (coef_df_map.assign(abs_coef=lambda d: d["coef"].abs())
                              .sort_values("abs_coef", ascending=False)
                              .head(10)
                              .sort_values("coef"))
        fig_b_map, ax_b_map = make_fig(5.2, max(2.6, len(top10)/12))
        ax_b_map.barh(top10["feature"], top10["coef"], xerr=1.96*top10["se"])
        ax_b_map.set_title("MAP Coefficients (Top 10 by |coef|) ¬±1.96¬∑SE")
        st.pyplot(fig_b_map, use_container_width=True)
        st.caption("**Thanh l·ªói** ‚âà ƒë·ªô b·∫•t ƒë·ªãnh t·ª´ Laplace. Thanh d√†i ‚Üí b·∫•t ƒë·ªãnh cao.")
    except Exception:
        st.info("Kh√¥ng v·∫Ω ƒë∆∞·ª£c sai s·ªë h·ªá s·ªë (Laplace).")

    # Save for Predict UI
    st.session_state["predict_mode"] = "laplace"
    st.session_state["preprocess"] = preprocess
    st.session_state["mle_pipe"] = mle_pipe
    st.session_state["map_pipe"] = map_pipe
    st.session_state["Sigma"] = Sigma
    st.session_state["w_map"] = w_map
    st.session_state["b_map"] = b_map
    st.session_state["feature_names_all"] = (numeric_cols, categorical_cols)

elif bayes_method == "PyMC sampling":
    if not _PYMC_AVAILABLE:
        st.error("PyMC/ArviZ ch∆∞a s·∫µn s√†ng trong m√¥i tr∆∞·ªùng n√†y.")
    else:
        # Build design matrices
        Xt_train = build_design_matrix(preprocess, X_train)
        Xt_test  = build_design_matrix(preprocess, X_test)
        try:
            with st.spinner("ƒêang sampling v·ªõi PyMC (c·∫ßn compiler 64-bit)..."):
                with pm.Model() as bayes_logit:
                    beta = pm.Normal("beta", mu=0, sigma=prior_sigma_beta_pymc, shape=Xt_train.shape[1])
                    intercept = pm.Normal("intercept", mu=0, sigma=prior_sigma_intercept_pymc)
                    logits = intercept + pm.math.dot(Xt_train, beta)
                    p = pm.math.sigmoid(logits)
                    y_obs = pm.Bernoulli("y_obs", p=p, observed=y_train.values)
                    idata = pm.sample(
                        draws=int(draws), tune=int(tune),
                        target_accept=float(target_accept),
                        chains=int(chains), cores=int(cores),
                        random_seed=42, progressbar=True
                    )
            st.success("‚úÖ PyMC fitted.")
            try:
                summ = az.summary(idata, var_names=["beta","intercept"], round_to=3)
                st.dataframe(summ.head(12))
            except Exception:
                st.info("Kh√¥ng th·ªÉ hi·ªÉn th·ªã b·∫£ng summary ArviZ.")

            beta_mean = idata.posterior["beta"].mean(dim=("chain","draw")).values
            intercept_mean = idata.posterior["intercept"].mean(dim=("chain","draw")).values
            logits_test = intercept_mean + Xt_test @ beta_mean
            proba_bayes = 1/(1+np.exp(-logits_test))
            y_pred_bayes = (proba_bayes >= 0.5).astype(int)

            acc_b  = accuracy_score(y_test, y_pred_bayes)
            prec_b = precision_score(y_test, y_pred_bayes, zero_division=0)
            rec_b  = recall_score(y_test, y_pred_bayes, zero_division=0)
            f1_b   = f1_score(y_test, y_pred_bayes, zero_division=0)
            auc_b  = roc_auc_score(y_test, proba_bayes)

            c1, c2, c3, c4 = st.columns(4)
            with c1: st.metric("Accuracy (Bayes)", f"{acc_b:.3f}")
            with c2: st.metric("Precision (Bayes)", f"{prec_b:.3f}")
            with c3: st.metric("Recall (Bayes)", f"{rec_b:.3f}")
            with c4: st.metric("F1 (Bayes)", f"{f1_b:.3f}")
            st.metric("ROC AUC (Bayes)", f"{auc_b:.3f}")
            st.caption("PyMC tr·∫£ v·ªÅ posterior ƒë·∫ßy ƒë·ªß ‚Üí c√≥ th·ªÉ tr√≠ch xu·∫•t CI & posterior predictive.")

            st.session_state["predict_mode"] = "pymc"
            st.session_state["preprocess"] = preprocess
            st.session_state["mle_pipe"] = mle_pipe
            st.session_state["idata"] = idata
            st.session_state["Xt_train_shape"] = Xt_train.shape
            st.session_state["feature_names_all"] = (numeric_cols, categorical_cols)

        except Exception as e:
            st.error("PyMC sampling failed.\n\n````\n%s\n````" % (str(e)[:1000]))
            st.info("‚ñ∂Ô∏è Auto-fallback to Bayesian (Laplace).")
            C_map = 100.0
            map_clf = LogisticRegression(penalty="l2", C=C_map, solver="lbfgs", max_iter=1000, class_weight=class_weight)
            map_pipe = Pipeline([("preprocess", preprocess), ("clf", map_clf)])
            map_pipe.fit(X_train, y_train)

            Z_train = build_design_matrix(preprocess, X_train)
            w_map = map_pipe.named_steps["clf"].coef_.ravel()
            b_map = float(map_pipe.named_steps["clf"].intercept_[0])
            Sigma = laplace_posterior(Z_train, w_map, b_map, prior_var_w=100.0, prior_var_b=100.0)

            st.session_state["predict_mode"] = "laplace"
            st.session_state["preprocess"] = preprocess
            st.session_state["mle_pipe"] = mle_pipe
            st.session_state["map_pipe"] = map_pipe
            st.session_state["Sigma"] = Sigma
            st.session_state["w_map"] = w_map
            st.session_state["b_map"] = b_map
            st.session_state["feature_names_all"] = (numeric_cols, categorical_cols)

# ========= Model Comparison =========
if "map_pipe" in st.session_state or ("idata" in st.session_state and _PYMC_AVAILABLE):
    st.header("‚öñÔ∏è Model Comparison (MLE vs Bayesian)")
    comp = []
    def safe_mets(name, y_true, proba, y_pred):
        d = {"Model": name,
             "Accuracy": accuracy_score(y_true, y_pred),
             "Precision": precision_score(y_true, y_pred, zero_division=0),
             "Recall": recall_score(y_true, y_pred, zero_division=0),
             "F1": f1_score(y_true, y_pred, zero_division=0)}
        try:
            d["ROC AUC"] = roc_auc_score(y_true, proba)
        except Exception:
            d["ROC AUC"] = np.nan
        return d

    # MLE
    comp.append(safe_mets("MLE", y_test, y_proba_mle, y_pred_mle))

    # Bayesian
    if "map_pipe" in st.session_state:
        p_map = st.session_state["map_pipe"].predict_proba(X_test)[:,1]
        comp.append(safe_mets("Bayesian (MAP/Laplace)", y_test, p_map, (p_map>=0.5).astype(int)))
    elif "idata" in st.session_state and _PYMC_AVAILABLE:
        Xt_test = build_design_matrix(st.session_state["preprocess"], X_test)
        beta_mean = st.session_state["idata"].posterior["beta"].mean(dim=("chain","draw")).values
        intercept_mean = st.session_state["idata"].posterior["intercept"].mean(dim=("chain","draw")).values
        logits_test = intercept_mean + Xt_test @ beta_mean
        p_bayes = 1/(1+np.exp(-logits_test))
        comp.append(safe_mets("Bayesian (PyMC mean)", y_test, p_bayes, (p_bayes>=0.5).astype(int)))

    st.dataframe(pd.DataFrame(comp).round(3))
    st.caption("**G·ª£i √Ω**: Ch·ªçn m√¥ h√¨nh theo m·ª•c ti√™u (v√≠ d·ª• Recall cao). N·∫øu ch√™nh l·ªách nh·ªè, ∆∞u ti√™n m√¥ h√¨nh ƒë∆°n gi·∫£n (MLE) ƒë·ªÉ tri·ªÉn khai d·ªÖ d√†ng.")

# ========= Threshold & Gains/Lift =========
st.header("üìè Threshold & Gains / Lift")
# Choose probability source: prefer Bayesian MAP if available, else MLE
if "map_pipe" in st.session_state:
    proba = st.session_state["map_pipe"].predict_proba(X_test)[:,1]
    src_name = "MAP (Laplace)"
else:
    proba = y_proba_mle if y_proba_mle is not None else None
    src_name = "MLE"

if proba is None:
    st.info("C·∫ßn x√°c su·∫•t (proba) ƒë·ªÉ ph√¢n t√≠ch ng∆∞·ª°ng. H√£y d√πng solver h·ªó tr·ª£ `predict_proba`.")
else:
    # Recommend threshold by maximizing F1
    cand = np.linspace(0.05, 0.95, 19)
    f1s = []
    for t in cand:
        y_t = (proba >= t).astype(int)
        f1s.append(f1_score(y_test, y_t, zero_division=0))
    t_rec = float(cand[int(np.argmax(f1s))])

    thr = st.slider(f"Decision threshold (using {src_name} probabilities)", 0.0, 1.0, t_rec, 0.01)
    y_thr = (proba >= thr).astype(int)
    mets = summarize_metrics(y_test, y_thr, proba)
    c1, c2, c3, c4 = st.columns(4)
    with c1: st.metric("Accuracy@thr", f"{mets['Accuracy']:.3f}")
    with c2: st.metric("Precision@thr", f"{mets['Precision']:.3f}")
    with c3: st.metric("Recall@thr", f"{mets['Recall']:.3f}")
    with c4: st.metric("F1@thr", f"{mets['F1']:.3f}")
    cm_thr = confusion_matrix(y_test, y_thr)
    st.write("**Confusion Matrix @ threshold**")
    st.write(pd.DataFrame(cm_thr, index=["Actual 0", "Actual 1"], columns=["Pred 0", "Pred 1"]))
    st.caption("**H∆∞·ªõng d·∫´n**: ‚Ä¢ ∆Øu ti√™n **Recall** ‚Üí k√©o ng∆∞·ª°ng ‚Üì. ‚Ä¢ ∆Øu ti√™n **Precision** ‚Üí k√©o ng∆∞·ª°ng ‚Üë. ‚Ä¢ F1 c√¢n b·∫±ng c·∫£ hai.")

    # Lift by decile
    df_scores = pd.DataFrame({"y": y_test.values, "score": proba})
    df_scores = df_scores.sort_values("score", ascending=False).reset_index(drop=True)
    df_scores["decile"] = pd.qcut(df_scores["score"].rank(method="first"), 10, labels=False)
    lift = df_scores.groupby("decile")["y"].mean()
    base = df_scores["y"].mean()
    fig_lift, ax_lift = make_fig(5.2, 3.2)
    ax_lift.plot(lift.index, lift.values/base, marker="o")
    ax_lift.axhline(1.0, linestyle="--")
    ax_lift.set_title(f"Lift by Decile ‚Äî {src_name}")
    ax_lift.set_xlabel("Decile (0 = top scored)")
    ax_lift.set_ylabel("Lift vs baseline")
    st.pyplot(fig_lift, use_container_width=True)
    st.caption("**Lift**: so s√°nh t·ªâ l·ªá d∆∞∆°ng t√≠nh trong m·ªói decile v·ªõi baseline (ƒë∆∞·ªùng ngang=1). Decile ƒë·∫ßu cao >>1 ch·ª©ng t·ªè m√¥ h√¨nh x·∫øp h·∫°ng t·ªët.")

# ========= Predict UI =========
st.header("üîÆ Predict on Custom Input")
if "preprocess" not in st.session_state:
    st.info("H√£y ch·∫°y hu·∫•n luy·ªán (MLE v√† m·ªôt bi·∫øn th·ªÉ Bayesian) tr∆∞·ªõc khi d·ª± ƒëo√°n.")
else:
    numeric_cols, categorical_cols = st.session_state["feature_names_all"]
    with st.form("predict_form"):
        input_data = {}
        for c in numeric_cols:
            try:
                col_min = float(pd.to_numeric(X_train[c], errors="coerce").min())
                col_max = float(pd.to_numeric(X_train[c], errors="coerce").max())
                col_mean = float(pd.to_numeric(X_train[c], errors="coerce").mean())
                step = (col_max-col_min)/100 if (col_max>col_min) else 1.0
                input_data[c] = st.number_input(f"{c} (numeric)", value=col_mean, min_value=col_min, max_value=col_max, step=step, help="Nh·∫≠p s·ªë; ƒë√£ ƒë∆∞·ª£c chu·∫©n ho√° trong pipeline.")
            except Exception:
                input_data[c] = st.number_input(f"{c} (numeric)", value=0.0)
        for c in categorical_cols:
            opts = sorted([str(x) for x in pd.Series(X_train[c]).dropna().unique().tolist()])
            input_data[c] = st.selectbox(f"{c} (categorical)", options=opts if opts else [""], index=0, help="Ch·ªçn m·ªôt trong c√°c gi√° tr·ªã ƒë√£ th·∫•y ·ªü train.")
        submitted = st.form_submit_button("Predict")

    if submitted:
        x_df = pd.DataFrame([input_data])
        mle_pipe = st.session_state["mle_pipe"]
        try:
            p_mle = float(mle_pipe.predict_proba(x_df)[0,1])
            y_mle = int(p_mle >= 0.5)
        except Exception:
            y_mle = int(mle_pipe.predict(x_df)[0])
            p_mle = np.nan

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("MLE")
            st.metric("Probability (class=1)", f"{p_mle:.3f}")
            st.metric("Label @ 0.5", "1" if y_mle==1 else "0")
            st.caption("B·∫°n c√≥ th·ªÉ d√πng ng∆∞·ª°ng kh√°c trong ph·∫ßn **Threshold**.")

        mode = st.session_state.get("predict_mode", "laplace")
        if mode == "laplace":
            preprocess = st.session_state["preprocess"]
            z = build_design_matrix(preprocess, x_df)
            z_aug = np.hstack([np.ones((1,1)), z])
            Sigma = st.session_state["Sigma"]
            theta_mean = np.concatenate([[st.session_state["b_map"]], st.session_state["w_map"]])
            m = float(z_aug @ theta_mean)
            v = float(z_aug @ Sigma @ z_aug.T)
            p_bayes = bayes_pred_prob_with_variance_correction(m, v)
            y_bayes = int(p_bayes >= 0.5)
            with c2:
                st.subheader("Bayesian (Laplace)")
                st.metric("Probability (var-corrected)", f"{p_bayes:.3f}")
                st.metric("Label @ 0.5", str(y_bayes))
                st.caption(f"Mean m={m:.3f}, variance v={v:.6f}. X√°c su·∫•t ƒë√£ ƒëi·ªÅu ch·ªânh theo b·∫•t ƒë·ªãnh.")
        elif mode == "pymc" and _PYMC_AVAILABLE and ("idata" in st.session_state):
            preprocess = st.session_state["preprocess"]
            z = build_design_matrix(preprocess, x_df)  # (1,d)
            idata = st.session_state["idata"]
            beta_draws = idata.posterior["beta"].values  # (chain, draw, d)
            intercept_draws = idata.posterior["intercept"].values  # (chain, draw)
            c, d, D = beta_draws.shape[0], beta_draws.shape[1], beta_draws.shape[2]
            samples = beta_draws.reshape(c*d, D)
            intercepts = intercept_draws.reshape(c*d)
            logits = intercepts + samples @ z.ravel()
            probs = 1/(1+np.exp(-logits))
            mean_p = float(np.mean(probs))
            lo, hi = float(np.quantile(probs, 0.025)), float(np.quantile(probs, 0.975))
            y_bayes = int(mean_p >= 0.5)

            with c2:
                st.subheader("Bayesian (PyMC)")
                st.metric("Mean probability", f"{mean_p:.3f}")
                st.metric("Label @ 0.5", str(y_bayes))
                st.caption(f"95% credible interval for p: [{lo:.3f}, {hi:.3f}]")
        else:
            with c2:
                st.subheader("Bayesian")
                st.info("Ch∆∞a c√≥ k·∫øt qu·∫£ Bayesian ƒë·ªÉ d·ª± ƒëo√°n (h√£y ch·∫°y Laplace ho·∫∑c PyMC).")

# ========= Download predictions =========
st.header("‚¨áÔ∏è Download Test Predictions")
out_df = X_test.copy()
out_df[target_col + "_true"] = y_test.values
out_df["pred_MLE"] = y_pred_mle
out_df["proba_MLE"] = y_proba_mle if y_proba_mle is not None else np.nan

if "map_pipe" in st.session_state:
    proba_map = st.session_state["map_pipe"].predict_proba(X_test)[:,1]
    pred_map = (proba_map >= 0.5).astype(int)
    out_df["pred_MAP"] = pred_map
    out_df["proba_MAP"] = proba_map
elif "idata" in st.session_state and _PYMC_AVAILABLE:
    Xt_test = build_design_matrix(st.session_state["preprocess"], X_test)
    beta_mean = st.session_state["idata"].posterior["beta"].mean(dim=("chain","draw")).values
    intercept_mean = st.session_state["idata"].posterior["intercept"].mean(dim=("chain","draw")).values
    logits_test = intercept_mean + Xt_test @ beta_mean
    proba_bayes = 1/(1+np.exp(-logits_test))
    pred_bayes = (proba_bayes >= 0.5).astype(int)
    out_df["pred_Bayes"] = pred_bayes
    out_df["proba_Bayes"] = proba_bayes

csv_bytes = out_df.to_csv(index=False).encode("utf-8")
st.download_button("Download CSV", data=csv_bytes, file_name="predictions_test.csv", mime="text/csv")

# ========= Playbooks & Glossary =========
with st.expander("üß≠ Tuning Playbooks (What to do when...)", expanded=False):
    st.markdown("""
- **Recall qu√° th·∫•p (b·ªè s√≥t nhi·ªÅu b·∫£n ghi l·ªõp 1)**  
  ‚Üí B·∫≠t **class_weight='balanced'**, **gi·∫£m ng∆∞·ª°ng** trong ph·∫ßn Threshold, ho·∫∑c thu th·∫≠p th√™m d·ªØ li·ªáu l·ªõp 1.
- **Precision qu√° th·∫•p (nhi·ªÅu false positive)**  
  ‚Üí **TƒÉng ng∆∞·ª°ng**; c√¢n nh·∫Øc **C nh·ªè h∆°n** (L2 m·∫°nh h∆°n) ƒë·ªÉ l√†m x√°c su·∫•t b·ªõt c·ª±c tr·ªã.
- **AUC/ROC th·∫•p**  
  ‚Üí Xem l·∫°i feature engineering; th√™m bi·∫øn, x·ª≠ l√Ω outlier, ho·∫∑c th·ª≠ m√¥ h√¨nh kh√°c.
- **Calibration l·ªách (ƒë∆∞·ªùng cong kh√¥ng g·∫ßn ch√©o)**  
  ‚Üí TƒÉng d·ªØ li·ªáu, th·ª≠ regularization m·∫°nh h∆°n, ho·∫∑c h·∫≠u hi·ªáu ch·ªânh (Platt/Isotonic).
- **H·ªá s·ªë kh√≥ di·ªÖn gi·∫£i**  
  ‚Üí Xem **Correlation**, hi·ªÉu baseline one-hot, ho·∫∑c b√°o c√°o theo **m·ª©c t√°c ƒë·ªông** (odds ratio = exp(coef)).
""")

with st.expander("üìñ Glossary", expanded=False):
    st.markdown("""
- **Accuracy**: (TP+TN)/(all). D·ªÖ ‚Äúƒë·∫πp‚Äù khi l·ªách l·ªõp n·∫∑ng ‚Üí c·∫©n th·∫≠n.
- **Precision**: TP/(TP+FP). Trong c√°c d·ª± ƒëo√°n ‚Äú1‚Äù, bao nhi√™u % ƒë√∫ng?
- **Recall (TPR)**: TP/(TP+FN). Trong c√°c b·∫£n ghi ‚Äú1‚Äù th·∫≠t, b·∫Øt ƒë∆∞·ª£c bao nhi√™u %?
- **F1**: H√†i ho√† Precision & Recall (th√≠ch h·ª£p khi l·ªách l·ªõp).
- **ROC AUC**: Kh·∫£ nƒÉng x·∫øp h·∫°ng ƒë√∫ng x√°c su·∫•t.
- **Lift**: T·ªâ l·ªá d∆∞∆°ng t√≠nh trong nh√≥m top-k so v·ªõi baseline ‚Üí ƒë√°nh gi√° kh·∫£ nƒÉng ∆∞u ti√™n.
- **Calibration**: S·ª± ph√π h·ª£p gi·ªØa x√°c su·∫•t d·ª± ƒëo√°n v√† t·∫ßn su·∫•t th·ª±c.
- **MAP/Laplace**: ∆Ø·ªõc l∆∞·ª£ng ƒëi·ªÉm c·ª±c ƒë·∫°i h·∫≠u nghi·ªám + x·∫•p x·ªâ Gaussian quanh n√≥ (nhanh).
- **PyMC**: L·∫•y m·∫´u ƒë·∫ßy ƒë·ªß posterior (ch·∫≠m h∆°n nh∆∞ng gi√†u th√¥ng tin).
""")

st.markdown("---")
st.caption("Plots are scaled via the sidebar slider. Each plot and section includes guidance to help you interpret and tune the model.")
